

<!DOCTYPE html>
<html>
<head>
	<meta name="generator" content="Hugo 0.26" />
    
    <meta charset="utf-8">
    <base href="http://xzh.me">
    <title>Xiang Zhang</title>
    <link rel="canonical" href="http://xzh.me/">
    <link href="http://xzh.me/index.xml" rel="alternate" type="application/rss+xml" title="Xiang Zhang" />

    

<link rel="stylesheet" href="/css/poole.css">
<link rel="stylesheet" href="/css/syntax.css">
<link rel="stylesheet" href="/css/lanyon.css">
<link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700|PT+Sans:400">

</head>
  <body class="theme-base-0d" lang="en">

  


<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">


<div class="sidebar" id="sidebar">

  <nav class="sidebar-nav">
    <a class="sidebar-nav-item" href="/">Home</a>

    <a class="sidebar-nav-item" href="/posts">Blog</a>
    
    <a class="sidebar-nav-item" href="http://www.github.com/zhangxiangxiao">Github</a>
    <a class="sidebar-nav-item" href="http://www.linkedin.com/in/zhangxiangxiao">LinkedIn</a>
    <a class="sidebar-nav-item" href="http://plus.google.com/+XiangZhang0">Google Plus</a>
    <a class="sidebar-nav-item" href="http://www.facebook.com/zhangxiangxiao">Facebook</a>
  </nav>

  <div class="sidebar-item">
    <p class="right credit">
      &copy; 2015 Xiang Zhang. Powered by <a href="http://hugo.spf13.com">Hugo</a>. Design adapted by Spencer Lyon from <a href="http://lanyon.getpoole.com">Lanyon</a>.
    </p>
  </div>
</div>


  
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="/" title="Xiang Zhang">Xiang Zhang</a>
          </h3>
        </div>
      </div>

      
      <div class="container content">
	<p>
	  <img class="left" src="images/xiang.jpg" style="width:25%;"> </img>
	  Xiang Zhang, Ph.D. Student <br />
	  <a href="http://cs.nyu.edu" >Computer Science Department</a> <br />
	  <a href="http://cims.nyu.edu">Courant Institute of Mathematical Sciences</a> <br />
	  <a href="http://www.nyu.edu">New York University</a> <br />
	  xiang.zhang (a t) nyu.edu <br />
	  60 5th Ave, Room 501, New York, NY 10003
	</p>

	<p>
	  I am a fifth year Ph.D. student under the advisement of professor <a href="http://yann.lecun.com/">Yann LeCun</a> with an interest in machine learning, including deep learning, numerical optimization, and some learning theory. Before being a Ph.D. student, I already spent 2 years as an M.S. student at NYU, during which time I participate in some research projects. Before coming to the U.S., I was an undergraduate student at the <a href="http://cs.tju.edu.cn">School of Computer Science and Technology</a>,
	  <a href="http://www.tju.edu.cn">Tianjin University</a>, conducting research in computational photography advised by professor <a href="http://cs.tju.edu.cn/faculty/lsg">Shiguang
	    Liu</a>.

	</p>
	<p><b>I am actively looking for an industrial research or post-doc position starting in October 2018 or later, especially in applying deep learning to natural language understanding, reasoning and generation. <a href="docs/resume.pdf">Here</a> is a resume.</b></p>

	
	<h1 class="post-title">News</h1>
	<p>
	  <ul>
	    <li>We published a new technical report titled <a href="https://arxiv.org/abs/1708.02657">"Which Encoding is the Best for Text Classification in Chinese, English, Japanese and Korean?"</a> on arXiv. It includes experiments on 473 text classification models using different levels and mechanisms of encoding Chinese, English, Japanese and Korean texts. There are also 14 large-scale datasets used in the article, with millions of samples each. Code and datasets are coming soon!</li>
	  </ul>
	</p>

	
	<h1 class="post-title">Refereed Publications</h1>
	<p class="head"><a href="https://scholar.google.com/citations?hl=en&user=n4QjVfoAAAAJ">Google Scholar profile</a></p>
	<p>
	  <ul>
            <li><strong>Xiang Zhang</strong>, Yann LeCun. <a href="https://arxiv.org/abs/1511.03719">Universum Prescription: Regularization using Unlabeled Data</a>. Thirty-First AAAI Conference on Artificial Intelligence (AAAI 2017). <a href="docs/universum.pdf">Slides</a>. </li>
            <li>Jesse Dodge, Andreea Gane, <strong>Xiang Zhang</strong>, Antoine Bordes, Sumit Chopra, Alexander Miller, Arthur Szlam, Jason Weston. <a href="https://arxiv.org/abs/1511.06931">Evaluating Prerequisite Qualities for Learning End-to-End Dialog Systems</a>. International Conference on Learning Representations (ICLR) 2016. <a href="http://fb.ai/babi">Datasets</a>.</li>
	    <li><strong>Xiang Zhang</strong>, Junbo Zhao, Yann LeCun. <a href="https://arxiv.org/abs/1509.01626">Character-level Convolutional Networks for Text Classification</a>. Advances in Neural Information Processing Systems 28 (NIPS 2015). <a href="docs/charconvnet.pdf">Poster</a>. <a href="http://goo.gl/JyCnZq">Datasets</a>. <a href="https://github.com/zhangxiangxiao/Crepe">Code</a>. <a href="http://xzh.me/posts/charconvneterrata">Errata</a>.</li>
	    <li>Pierre Sermanet, David Eigen, <strong>Xiang Zhang</strong>, Michaël Mathieu, Rob Fergus, Yann LeCun. <a href="https://arxiv.org/abs/1312.6229">OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks</a>. International Conference on Learning Representations (ICLR) 2014.</li>
	    <li>Shiguang Liu, <strong>Xiang Zhang</strong>. <a href="http://reviews.spiedigitallibrary.org/article.aspx?articleid=1558565">Image Colorization Based on Texture Map</a>. Journal of Electronic Imaging, 2013, Volume 22, Issue 1, 01311.</li>
	    <li>Shiguang Liu, <strong>Xiang Zhang</strong>. <a href="http://www.sciencedirect.com/science/article/pii/S0167865512001894">Automatic Grayscale Image Colorization using Histogram Regression</a>. Pattern Recognition Letters, 2012, Volume 33, Issue 13, Pages 1673-1681.</li>
	    <li>Shiguang Liu, Hanqiu Sun, <strong>Xiang Zhang</strong>. <a href="http://www.sciencedirect.com/science/article/pii/S1047320311001222">Selective color transferring via ellipsoid color mixture map</a>. Journal of Visual Communication and Image Representation, 2012, Volume 23, Issue 1, Pages 173-181.</li>
	    <li><strong>Xiang Zhang</strong>, Ce Yu. <a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6133207">Fast n-point Correlation Function Approximation with Recursive Convolution for Scalar Fields</a>. In IEEE Cloud Computing Technology and Science (CloudCom) CloudCom 2011, Pages 634-639.</li>
	    <li><strong>Xiang Zhang</strong>, Shiguang Liu, <a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6005562">Texture Transfer in Frequency Domain</a>. IEEE 2011 Sixth International Conference on Image and Graphics(ICIG), Pages 123-128.</li>
	    <li>Shiguang Liu, <strong>Xiang Zhang</strong>, Jingting Wu, Jizhou Sun, Qunsheng Peng, <a href="http://www.cjig.cn/jig/ch/reader/view_abstract.aspx?file_no=100564">Gray-scale Image Colorization based on the Control of Single-parameter</a>. Journal of Image and Graphics (In Chinese), 2011, Volume 16(7), Pages 1297-1302.</li>
	  </ul>
	</p>

        
	<h1 class="post-title">Technical Reports</h1>
        <p class="head"><a href="https://arxiv.org/a/zhang_x_4">arXiv profile</a></p>
	<p>
	  <ul>
            <li><strong>Xiang Zhang</strong>, Yann LeCun. <a href="https://arxiv.org/abs/1708.02657">Which Encoding is the Best for Text Classification in Chinese, English, Japanese and Korean?</a>. arXiv 1708.02657.</li>
            <li><strong>Xiang Zhang</strong>, Yann LeCun. <a href="https://arxiv.org/abs/1502.01710">Text Understanding from Scratch</a>. arXiv 1502.01710. <a href="http://goo.gl/JyCnZq">Datasets</a>. <a href="https://github.com/zhangxiangxiao/Crepe">Code</a>.</li>
	  </ul>
	</p>
	  
	<h1 class="post-title">Thesis</h1>
	<p>
	  <ul>
	    <li>M.S. Thesis: <a href="docs/master.pdf">PAC-learning for Energy-based Models</a>. Advisor: professor <a href="http://yann.lecun.com">Yann LeCun</a>. Reader: professor <a href="http://cs.nyu.edu/~dsontag/">David Sontag</a>.</li>
	    <li>2011 Best Undergraduate Thesis: <a href="docs/undergrad.pdf">Automatic Grayscale Image and Video Colorization (In Chinese)</a>. Advisor: professor <a href="http://cs.tju.edu.cn/faculty/lsg">Shiguang Liu</a>. <a href="docs/agic-matlab-0.6.tar.gz">Code</a>.</li>
	  </ul>
	</p>
        
        <h1 class="post-title">Blog Posts</h1>
          <section id="main">
            <ul id="list">
              
              

<article class="post">
    <header>
      <h2><a href='http://xzh.me/posts/charconvneterrata/'> Errata for Character-level Convolutional Networks for Text Classification</a> </h2>
      <div class="meta">Sun, Apr 3, 2016</div>
    </header>

    This page contains errata for the paper &ldquo;Xiang Zhang, Junbo Zhao, Yann LeCun. Character-level Convolutional Networks for Text Classification. Advances in Neural Information Processing Systems 28 (NIPS 2015)&ldquo;. The paper on arXiv server will be updated accordingly, but the paper in NIPS proceedings may stay as is. Some of the errata may also apply to our earlier technical report &ldquo;Xiang Zhang, Yann LeCun. Text Understanding from Scratch. arXiv 1502.01710.&rdquo;
 The upper index for the convolution and max-pooling module should be \( \lfloor (l-k)/d \rfloor + 1 \) instead of \( \lfloor (l-k+1)/d \rfloor \).
    <footer>
        <a href='http://xzh.me/posts/charconvneterrata/'><nobr>Read more →</nobr></a>
    </footer>
</article>

              
              

<article class="post">
    <header>
      <h2><a href='http://xzh.me/posts/commonsense/'> Common Sense: Unsupervised Learning or Machine Evolution?</a> </h2>
      <div class="meta">Thu, Jan 28, 2016</div>
    </header>

    Today I saw a post from Mark Zuckerberg on his project of automating a home. That great project is so awesome that it could probably change the future of human living. Along with the post there are arguments that common sense may be obtained through unsupervised learning. But personally I do not buy these arguments, at least not in the current form of unsupervised learning.
The intuition that a model can obtain common sense through unsupervised process is not straightforward to me.
    <footer>
        <a href='http://xzh.me/posts/commonsense/'><nobr>Read more →</nobr></a>
    </footer>
</article>

              
              

<article class="post">
    <header>
      <h2><a href='http://xzh.me/posts/evolvetosum/'> Evolve to Sum</a> </h2>
      <div class="meta">Sat, Jan 23, 2016</div>
    </header>

    Here is one simple question: how to make machines learn to sum up two numbers? Of course, this problem largely depends on how the numbers are represented. If they are represented in some finite-precision float-point format, a simple regression where both weights are one would solve the problem. But that&rsquo;s not what I mean here. What I mean is, given the symbolic representation of numbers (i.e., each number is a sequence of digits), how could a machine learn to sum them up?
    <footer>
        <a href='http://xzh.me/posts/evolvetosum/'><nobr>Read more →</nobr></a>
    </footer>
</article>

              
              

<article class="post">
    <header>
      <h2><a href='http://xzh.me/posts/emperorsnewmind/'> On the Emperor&#39;s New Mind</a> </h2>
      <div class="meta">Sun, Jul 12, 2015</div>
    </header>

    Finally finished reading Roger Penrose&rsquo;s classic book &ldquo;The Emperor&rsquo;s New Mind: Concerning Computers, Minds and The Laws of Physics&rdquo;. As a junior Ph.D. student who hopes to have a career in the research of artificial intelligence (machine learning or deep learning more precisely), I was reading this book as a touch on the opposite of the belief that intelligence is achievable by machines. Apart from several of his dramatic tones towards mocking A.
    <footer>
        <a href='http://xzh.me/posts/emperorsnewmind/'><nobr>Read more →</nobr></a>
    </footer>
</article>

              
              

<article class="post">
    <header>
      <h2><a href='http://xzh.me/posts/precondition/'> One Precondition for Intelligence</a> </h2>
      <div class="meta">Tue, Apr 21, 2015</div>
    </header>

    Medical study shows that two consciousness could exist in the same body, if the connection between the left and the right brain hemispheres are damaged. Does this medical fact tells us something more about intelligence? My opinion is, it is an evidence for the hypothesis that certain deficiency in low-level communication is a precondition for intelligence. I know that sounds crazy or perhaps hard to understand, but please allow me to explain.
    <footer>
        <a href='http://xzh.me/posts/precondition/'><nobr>Read more →</nobr></a>
    </footer>
</article>

              
              

<article class="post">
    <header>
      <h2><a href='http://xzh.me/posts/datasetdup/'> Dataset Duplication Issues for Text Understanding from Scratch (Resolved)</a> </h2>
      <div class="meta">Tue, Apr 7, 2015</div>
    </header>

    Update June 8th 2015: The dataset duplication issues are fixed in the latest revision of our technical report. Some of our large-scale datasets became smaller than before, but the general conclusion in the technical report still holds. The information below is retained for your reference, although they are no longer valid. We are working on extending comparisons with stronger baseline models and releasing the datasets as soon as possible.
    <footer>
        <a href='http://xzh.me/posts/datasetdup/'><nobr>Read more →</nobr></a>
    </footer>
</article>

              
              

<article class="post">
    <header>
      <h2><a href='http://xzh.me/posts/aprilfoolrnn/'> On April Fool&#39;s: What is Wrong with RNN?</a> </h2>
      <div class="meta">Wed, Apr 1, 2015</div>
    </header>

    Google&rsquo;s April fool surprise: reading characters in reverse order (https://com.google/).
It happened to be the case that the character order in Crepe (https://github.com/zhangxiangxiao/Crepe) is also reversed.
The original thought was that aligning the end of a document to a fixed position (in this case at the beginning) could make it easier for the fully-connected layers to associate meaning with the ending context window.
This may have the effect of biasing classification towards the end reading of a text, which has a somewhat distant relationship with how recurrent neural network representation can be used for classification, since it decays the influence of document at the beginning but not so much at the end.
    <footer>
        <a href='http://xzh.me/posts/aprilfoolrnn/'><nobr>Read more →</nobr></a>
    </footer>
</article>

              
              

<article class="post">
    <header>
      <h2><a href='http://xzh.me/posts/deeplearninglandscape/'> The Landscape of Deep Learning</a> </h2>
      <div class="meta">Tue, Jan 27, 2015</div>
    </header>

    This blog summarizes an answer I posted to a question regarding what kinds of research are there for deep learning, in Zhihu, a Chinese equivalence of Quora. Surprisingly, that answer drew a lot of attention from many students and young researchers in China and it is currently ranked the second best answer in the subcategory of &ldquo;deep learning&rdquo;. I hope the summarization here could offer my bit of thought to a broader audience by translating that answer to English.
    <footer>
        <a href='http://xzh.me/posts/deeplearninglandscape/'><nobr>Read more →</nobr></a>
    </footer>
</article>

              
            </ul>
          </section>
      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>



<div class="container content">
<footer>
  <div>
    <p class="right credit">
      Profile in: 
      <a href="http://www.github.com/zhangxiangxiao">Github</a> | 
      <a href="http://www.linkedin.com/in/zhangxiangxiao">LinkedIn</a> |
      <a href="https://plus.google.com/+XiangZhang0">Google Plus</a> | 
      <a href="http://www.facebook.com/zhangxiangxiao">Facebook</a>
    </p>
  </div>
</footer>
</div>


<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-59001618-1', 'auto');
  ga('send', 'pageview');

</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[','\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    // Fix <code> tags after MathJax finishes running. This is a
    // hack to overcome a shortcoming of Markdown. Discussion at
    // https://github.com/mojombo/jekyll/issues/199
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i &lt; all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



</body>
</html>

