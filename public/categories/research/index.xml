<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Research on Xiang Zhang</title>
    <link>http://xzh.me/categories/research/</link>
    <description>Recent content in Research on Xiang Zhang</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Tue, 07 Apr 2015 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://xzh.me/categories/research/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Dataset Duplication Issues for Text Understanding from Scratch</title>
      <link>http://xzh.me/posts/datasetdup/</link>
      <pubDate>Tue, 07 Apr 2015 00:00:00 +0000</pubDate>
      
      <guid>http://xzh.me/posts/datasetdup/</guid>
      <description>

&lt;p&gt;On April 6th 2015, we discovered some issues related to the datasets used in our technical report &lt;a href=&#34;http://arxiv.org/abs/1502.01710&#34;&gt;&amp;ldquo;Text Understanding from Scratch&amp;rdquo;&lt;/a&gt;. These issues include multiple instances of the same sample, and overlaps between training and testing data. These issues were first discovered by Alec Radford, head of research at &lt;a href=&#34;https://indico.io&#34;&gt;indico&lt;/a&gt;, who carefully checked a few of our released datasets and found them. I want offer my thanks to him.&lt;/p&gt;

&lt;p&gt;Here is what I am going to do to solve this issue:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Remove Amazon review and Sogou news datasets from release. The DBPedia dataset is completely clean.&lt;/li&gt;
&lt;li&gt;Put a notification in our technical report&amp;rsquo;s first page, untill we can resolve these issues and obtain new experiment results. This is already submitted to arXiv, but it may take a few days to appear online.&lt;/li&gt;
&lt;li&gt;Solve the issues in the datasets, and redo all related experiments.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I apologize for any inconvenience and inaccurate information resulted from this. I am aware that this technical report drew a lot of attention from fellow researchers all around the world, and I will do my best to resolve the issues as soon as possible.&lt;/p&gt;

&lt;h3 id=&#34;what-are-the-issues:6d4327301e838a9c8bdd4a7eb0a3f227&#34;&gt;What are the issues?&lt;/h3&gt;

&lt;p&gt;As said before, the issues are multiple instances of the same sample, and overlaps between training and testing data. I am still investigating the reasons behind these issues, but so far it looks like there were duplications from the datasets&amp;rsquo; original owners and distributors. Below is a break down of the issues for the datasets in the original technical report.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;DBPedia&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Duplication in Train: 0 of 560000, 0 %&lt;/li&gt;
&lt;li&gt;Duplication in Test: 0 of 70000, 0 %&lt;/li&gt;
&lt;li&gt;Overlap: 0 of 70000, 0%&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Yahooo Answers&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Duplication in Train: 434 of 1400000, 0%&lt;/li&gt;
&lt;li&gt;Duplication in Test: 0 of 50000, 0%&lt;/li&gt;
&lt;li&gt;Overlap: 32 of 50000, 0%&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Amazon Review Full Score&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Duplication in Train: 1434980 of 5000000, 29%&lt;/li&gt;
&lt;li&gt;Duplication in Test: 175671 of 1250000, 14%&lt;/li&gt;
&lt;li&gt;Overlap: 513193 of 1250000, 41%&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Amazon Review Polarity&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Duplication in Train: 1854042 of 6000000, 31%&lt;/li&gt;
&lt;li&gt;Duplication in Test: 162916 of 900000, 18%&lt;/li&gt;
&lt;li&gt;Overlap: 352296 of 900000, 39%&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;AGNews Corpus&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Duplication in Train: 13423 of 160000, 8%&lt;/li&gt;
&lt;li&gt;Duplication in Test: 16 of 4400, 0%&lt;/li&gt;
&lt;li&gt;Overlap: 655 of 4400, 15%&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Sogou News Corpus&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Duplication in Train: 194783 of 750000, 26%&lt;/li&gt;
&lt;li&gt;Duplication in Test: 6876 of 50000, 14%&lt;/li&gt;
&lt;li&gt;Overlap: 15789 of 50000, 32%&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;is-the-crepe-code-affected:6d4327301e838a9c8bdd4a7eb0a3f227&#34;&gt;Is the Crepe code affected?&lt;/h3&gt;

&lt;p&gt;The release of &lt;a href=&#34;https://github.com/zhangxiangxiao/Crepe&#34;&gt;Crepe&lt;/a&gt; is idependent of the datasets. It is currently not affected by this issue. Also, because the DBPedia dataset is clean, the example usage for Crepe is still totally valid. The DBPedia dataset is kept online.&lt;/p&gt;

&lt;p&gt;That said, if you found bugs or issues with Crepe code, please let me know.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>