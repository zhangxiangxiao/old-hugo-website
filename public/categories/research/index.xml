<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Research on Xiang Zhang</title>
    <link>http://xzh.me/categories/research/</link>
    <description>Recent content in Research on Xiang Zhang</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Thu, 28 Jan 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://xzh.me/categories/research/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Common Sense: Unsupervised Learning or Machine Evolution?</title>
      <link>http://xzh.me/posts/commonsense/</link>
      <pubDate>Thu, 28 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>http://xzh.me/posts/commonsense/</guid>
      <description>&lt;p&gt;Today I saw a post from Mark Zuckerberg on his project of automating a home. That great project is so awesome that it could probably change the future of human living. Along with the post there are arguments that common sense may be obtained through unsupervised learning. But personally I do not buy these arguments, at least not in the current form of unsupervised learning.&lt;/p&gt;

&lt;div id=&#34;fb-root&#34;&gt;&lt;/div&gt;&lt;script&gt;(function(d, s, id) {  var js, fjs = d.getElementsByTagName(s)[0];  if (d.getElementById(id)) return;  js = d.createElement(s); js.id = id;  js.src = &#34;//connect.facebook.net/en_US/sdk.js#xfbml=1&amp;version=v2.3&#34;;  fjs.parentNode.insertBefore(js, fjs);}(document, &#39;script&#39;, &#39;facebook-jssdk&#39;));&lt;/script&gt;&lt;div class=&#34;fb-post&#34; data-href=&#34;https://www.facebook.com/zuck/posts/10102620559534481&#34; data-width=&#34;500&#34;&gt;&lt;div class=&#34;fb-xfbml-parse-ignore&#34;&gt;&lt;blockquote cite=&#34;https://www.facebook.com/zuck/posts/10102620559534481&#34;&gt;&lt;p&gt;My personal challenge for 2016 is to build a simple AI -- like Jarvis from Iron Man -- to help run my home and help me...&lt;/p&gt;Posted by &lt;a href=&#34;https://www.facebook.com/zuck&#34;&gt;Mark Zuckerberg&lt;/a&gt; on&amp;nbsp;&lt;a href=&#34;https://www.facebook.com/zuck/posts/10102620559534481&#34;&gt;Wednesday, January 27, 2016&lt;/a&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The intuition that a model can obtain common sense through unsupervised process is not straightforward to me. If that intuition came from how we human beings obtain common sense, a large portion of it came from a well-designed and strongly-supervised form of teaching and learning in school. Even prior to school, we learn via a feedback process with the world we interact, and at the same time under a strongly-supervised &amp;lsquo;protection&amp;rsquo; from our parents. There are many many different feedback signals available to us.&lt;/p&gt;

&lt;p&gt;On the other hand, if we think about the entire knowledge of human race, common sense seems to come unsupervisedly in the sense that we generate it via thousands years of evolution. But again that relies on the fact that the human race is not a single individual &amp;ndash; it consists of many many individuals and only through this complicated dynamic system we form what we today call common sense. Therefore it seems to miss the point to ask a single unsupervised model to generate all of common sense.&lt;/p&gt;

&lt;p&gt;However, I also feel that this seemingly unsupervised process of evolution is not feedback-free. Any living creature had to strive for maintain its low-entropy state (a structured state constituting of cells and their internal orderly structure), and release high-entropy waste to the environment via metabolism. Massive energy is used by such a creature during the process. It is through the will of better maintaining this low-entropy state that we evolve. Of course, machines do not have to do this, they just have to make &amp;lsquo;surving humans&amp;rsquo; as their ultimate goal.&lt;/p&gt;

&lt;p&gt;But the question is, how do we design a race of machines such that they can evolve to better surve us? And if this is possible, will the evolving machine population generate things similar to the phenomenon of &amp;lsquo;common sense&amp;rsquo;?&lt;/p&gt;

&lt;p&gt;P.S. Ultimately I feel it is meaningless to argue about whether something is supervised or unsupervised. In current form of machine learning one always needs to do optimization, therefore one needs to design an objective. We can always argue that the objective is a kind of supervised signal. The mindset of labeling something as &amp;lsquo;unsupervised&amp;rsquo; more or less misled us to think less about the mechanism of how some intelligent really phenonmena happened.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Evolve to Sum</title>
      <link>http://xzh.me/posts/evolvetosum/</link>
      <pubDate>Sat, 23 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>http://xzh.me/posts/evolvetosum/</guid>
      <description>

&lt;p&gt;Here is one simple question: how to make machines learn to sum up two numbers? Of course, this problem largely depends on how the numbers are represented. If they are represented in some finite-precision float-point format, a simple regression where both weights are one would solve the problem. But that&amp;rsquo;s not what I mean here. What I mean is, given the symbolic representation of numbers (i.e., each number is a sequence of digits), how could a machine learn to sum them up?&lt;/p&gt;

&lt;p&gt;There have been research projects in this realm, but the results are far from satisfactory and none of them can produce a machine that can sum up two numbers of arbitrary length. In this blog I want to offer an alternative view of this problem by dichotomizing learning into individual learning and evolutionary learning. Then, I provide an initial thought on the possibility of a new learning paradigm that is inspired not only from how each of us learns, but also how knowledge is formed during the entire human evolutionary process.&lt;/p&gt;

&lt;h3 id=&#34;learning-to-sum:f4c76188421e5843dda1963eace05e1c&#34;&gt;Learning to Sum&lt;/h3&gt;

&lt;p&gt;Yesterday I was invited to &lt;a href=&#34;https://www.zhihu.com/question/39727411/answer/82778981&#34;&gt;answer a question on Zhihu&lt;/a&gt;, a Chinese equivalent of Quora, about whether deep learning models can be used to learn to sum. Immediately I thought that the question is actually more difficult to answer than it appears to be, partly because it is always easier to disprove the possibility of something than to prove it.&lt;/p&gt;

&lt;p&gt;Knowing that we have very limited results in learning arithmetic operations, I started to recall a thought inspired by the book &amp;ldquo;Probably Approximately Correct: Natureâ€™s Algorithms for Learning and Prospering in a Complex World&amp;rdquo;, written by Turing award laureate Leslie G. Valiant. The book is mainly about an analogy of the probably approximately correct (PAC) learning theory and the evolutionary process of human beings. But my thought is only tangentially related to this analogy. It is more about a limitation on the current connectionist machine learning paradigm in relation to the dichotomy of individual learning and evolutionay process.&lt;/p&gt;

&lt;p&gt;It is better explained using the problem in question &amp;ndash; summation. The way each of us learns arithmetic operations such as summation is not quite what connectionist machine learning paradigm advocates &amp;ndash; end-to-end learning by showing result examples of two numbers summing together. Rather, we learn arithmetic operations via a strongly supervised process with the help of our math teachers in elementary school. When learning to sum, each of us were not only presented with examples of correct or incorrect sums, but also the proceeding steps of this arithmetic operation. If we were to train a deep learning model to do summation in this way, we would start with perhaps a simple recurrent neural net, design a process for this network to do summation, and train the network using samples of this process in a strongly supervised fashion. We can think of ourselves as the math teachers of this student recurrent neural network, teaching it not only right from wrong but also the steps to make it right.&lt;/p&gt;

&lt;p&gt;What is missing in the learning process above is the question of where summation comes from, or even where the concept of numbers comes from. We can find inspiration of such questions in humans, but it would no longer be possible to think of it in the scope of each human individual. Rather, we would have to think of human race as a whole and find answers in its entire evolutionary process. The answer of such questions immediately becomes demystified in this way of thinking, in that the concept of numbers and the process of arithmetic comes from generations of historical human activities. First of all, there is necessity of counting because we have learnt to produce and store goods. That was the reason for the concept of numbers. Then, when human society is developed enough for each individual to produce extra goods than for himself, there comes trading. Arithmetic naturally becomes a necessity, and since then we started to dissemminate the correct way of doing arithmetic until there is education and we started to teach it generation by generation. The description here is an extremely condensed version, and a better storytellling can be found in &lt;a href=&#34;http://www.bbc.co.uk/programmes/b00dwf4f&#34;&gt;BBC&amp;rsquo;s documentary &amp;lsquo;The Story of Maths&amp;rsquo;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The discussion above also hints on one problem of current generation deep learning research. The learning paradigm we used to design models is unexceptionally individual learning. One may argue that there is some aspect of deep learning models which implements some of evolution&amp;rsquo;s achievements &amp;ndash; such as convolutional network implements an analogy of our visual cortex (not the eye &amp;ndash; the eye is analogized by a camera). But this is only a slighly blurred line between individual learning and evolutionary learning. It is apparently impossible for evolution to be responsible for every part of the visual system &amp;ndash; maybe some lower layers that detect edges, but definitely not the upper layers where we form concepts and classification of objects. It does not disprove the necessity of a evolutionary learning paradigm.&lt;/p&gt;

&lt;h3 id=&#34;evolve-to-sum:f4c76188421e5843dda1963eace05e1c&#34;&gt;Evolve to Sum&lt;/h3&gt;

&lt;p&gt;Summation and other arithmetic operations are not the only things that evolutionary learning models. Common sense, culture, art and language &amp;ndash; traditionally hard to model by connectionist ideas &amp;ndash; could also be thought of as by-products of human evolution. If we have a way to let machines to evolve themselves, it may generate its own common sense, culture and art. This is not at all what evolutionary algorithm is about &amp;ndash; we are talking about evolution of models in a more literal sense.&lt;/p&gt;

&lt;p&gt;Admittedly, there are many problems that are unclear about an evolutionary learning process. The first one is whether there is an objective for machine evolution. I personally think that this is more about what the models should do rather than what is the optimization objective. Like human beings, the goal of a machine should be about survival in the world it exists. This suggests a different design principle for machines &amp;ndash; rather than to design machines to assist our daily lives, we would design machines that strive to surve themselves. It means we must equip machines with the ability of control its own survival needs. In the context of our current generation eletronic technology, one way to do this is probably equip it with the ability to plug itself into power outlets, at least mechanically. Then, we can use our current machine learning methods to let it learn how to get plugged with power in its software.&lt;/p&gt;

&lt;p&gt;The second problem is how could machines reproduce, since only with reproduction we would have generations of machines to constitute the process of evolution. One cheap way to do this is probably take over reproduction ourselves. We can keep producing copies of such machines, and evolution becomes choosing the best surviving learning machines to initialize the new ones. When technology is advanced enough, there will probably be a time that one of the machine will learn to reproduce by themselves, but we probably would not want to give the machines such ability.&lt;/p&gt;

&lt;p&gt;The last problem is what the software of such machines should look like. I believe it should consist of three parts: perception, reasoning and action. The perception part could be on vision or sound, and there are already many models in research for this. The reasoning part is relatively new, including perhaps the current trend on using embedding and memory techniques. As for the action part, there are at least two potential models &amp;ndash; recurrent neural networks and reinforcement learning. One attempts to model the past, and the other tries to predict the future reward.&lt;/p&gt;

&lt;p&gt;Now, let&amp;rsquo;s go back to the question of learning to sum. How can we discover whether the machine can do sum? Well, I think the question is probably wrong. A better question is probably this: is computing summation a necessity for the evolution of machines?&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Dataset Duplication Issues for Text Understanding from Scratch (Resolved)</title>
      <link>http://xzh.me/posts/datasetdup/</link>
      <pubDate>Tue, 07 Apr 2015 00:00:00 +0000</pubDate>
      
      <guid>http://xzh.me/posts/datasetdup/</guid>
      <description>

&lt;ul&gt;
&lt;li&gt;Update June 8th 2015: The dataset duplication issues are fixed in the &lt;a href=&#34;http://arxiv.org/abs/1502.01710&#34;&gt;latest revision of our technical report&lt;/a&gt;. Some of our large-scale datasets became smaller than before, but the general conclusion in the technical report still holds. The information below is retained for your reference, although they are no longer valid. We are working on extending comparisons with stronger baseline models and releasing the datasets as soon as possible.&lt;/li&gt;
&lt;li&gt;Update April 9th 2015: In wake of dataset duplication issues for the Amazon reviews dataset, professor &lt;a href=&#34;http://cseweb.ucsd.edu/~jmcauley&#34;&gt;Julian McAuley&lt;/a&gt; updated their &lt;a href=&#34;http://snap.stanford.edu/data/web-Amazon.html&#34;&gt;SNAP Amazon reviews dataset distribution webpage&lt;/a&gt; with an extra note and an extra data duplication file.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;On April 6th 2015, we discovered some issues related to the datasets used in our technical report &lt;a href=&#34;http://arxiv.org/abs/1502.01710&#34;&gt;&amp;ldquo;Text Understanding from Scratch&amp;rdquo;&lt;/a&gt;. These issues include multiple instances of the same sample, and overlaps between training and testing data. These issues were first discovered by Alec Radford, head of research at &lt;a href=&#34;https://indico.io&#34;&gt;indico&lt;/a&gt;, who carefully checked a few of our released datasets and found them. I want offer my thanks to him.&lt;/p&gt;

&lt;p&gt;Here is what I am going to do to solve this issue:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Remove Amazon review and Sogou news datasets from release. The DBPedia dataset is completely clean.&lt;/li&gt;
&lt;li&gt;Put a notification in our technical report&amp;rsquo;s first page, untill we can resolve these issues and obtain new experiment results. This is already submitted to arXiv, but it may take a few days to appear online.&lt;/li&gt;
&lt;li&gt;Solve the issues in the datasets, and redo all related experiments.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I apologize for any inconvenience and inaccurate information resulted from this. I am aware that this technical report drew a lot of attention from fellow researchers all around the world, and I will do my best to resolve the issues as soon as possible.&lt;/p&gt;

&lt;h3 id=&#34;what-are-the-issues:6d4327301e838a9c8bdd4a7eb0a3f227&#34;&gt;What are the issues?&lt;/h3&gt;

&lt;p&gt;As said before, the issues are multiple instances of the same sample, and overlaps between training and testing data. I am still investigating the reasons behind these issues, but so far it looks like there were duplications from the datasets&amp;rsquo; original owners and distributors. Below is a break down of the issues for the datasets in the original technical report.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;DBPedia&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Duplication in Train: 0 of 560000, 0 %&lt;/li&gt;
&lt;li&gt;Duplication in Test: 0 of 70000, 0 %&lt;/li&gt;
&lt;li&gt;Overlap: 0 of 70000, 0%&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Yahooo Answers&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Duplication in Train: 434 of 1400000, 0%&lt;/li&gt;
&lt;li&gt;Duplication in Test: 0 of 50000, 0%&lt;/li&gt;
&lt;li&gt;Overlap: 32 of 50000, 0%&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Amazon Review Full Score&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Duplication in Train: 1434980 of 5000000, 29%&lt;/li&gt;
&lt;li&gt;Duplication in Test: 175671 of 1250000, 14%&lt;/li&gt;
&lt;li&gt;Overlap: 513193 of 1250000, 41%&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Amazon Review Polarity&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Duplication in Train: 1854042 of 6000000, 31%&lt;/li&gt;
&lt;li&gt;Duplication in Test: 162916 of 900000, 18%&lt;/li&gt;
&lt;li&gt;Overlap: 352296 of 900000, 39%&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;AGNews Corpus&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Duplication in Train: 13423 of 160000, 8%&lt;/li&gt;
&lt;li&gt;Duplication in Test: 16 of 4400, 0%&lt;/li&gt;
&lt;li&gt;Overlap: 655 of 4400, 15%&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Sogou News Corpus&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Duplication in Train: 194783 of 750000, 26%&lt;/li&gt;
&lt;li&gt;Duplication in Test: 6876 of 50000, 14%&lt;/li&gt;
&lt;li&gt;Overlap: 15789 of 50000, 32%&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;is-the-crepe-code-affected:6d4327301e838a9c8bdd4a7eb0a3f227&#34;&gt;Is the Crepe code affected?&lt;/h3&gt;

&lt;p&gt;The release of &lt;a href=&#34;https://github.com/zhangxiangxiao/Crepe&#34;&gt;Crepe&lt;/a&gt; is idependent of the datasets. It is currently not affected by this issue. Also, because the DBPedia dataset is clean, the example usage for Crepe is still totally valid. The DBPedia dataset is kept online.&lt;/p&gt;

&lt;p&gt;That said, if you found bugs or issues with Crepe code, please let me know.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>