<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Intelligence on Xiang Zhang</title>
    <link>http://xzh.me/categories/intelligence/</link>
    <description>Recent content in Intelligence on Xiang Zhang</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Thu, 28 Jan 2016 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="http://xzh.me/categories/intelligence/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Common Sense: Unsupervised Learning or Machine Evolution?</title>
      <link>http://xzh.me/posts/commonsense/</link>
      <pubDate>Thu, 28 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>http://xzh.me/posts/commonsense/</guid>
      <description>Today I saw a post from Mark Zuckerberg on his project of automating a home. That great project is so awesome that it could probably change the future of human living. Along with the post there are arguments that common sense may be obtained through unsupervised learning. But personally I do not buy these arguments, at least not in the current form of unsupervised learning.
The intuition that a model can obtain common sense through unsupervised process is not straightforward to me.</description>
    </item>
    
    <item>
      <title>Evolve to Sum</title>
      <link>http://xzh.me/posts/evolvetosum/</link>
      <pubDate>Sat, 23 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>http://xzh.me/posts/evolvetosum/</guid>
      <description>Here is one simple question: how to make machines learn to sum up two numbers? Of course, this problem largely depends on how the numbers are represented. If they are represented in some finite-precision float-point format, a simple regression where both weights are one would solve the problem. But that&amp;rsquo;s not what I mean here. What I mean is, given the symbolic representation of numbers (i.e., each number is a sequence of digits), how could a machine learn to sum them up?</description>
    </item>
    
    <item>
      <title>On the Emperor&#39;s New Mind</title>
      <link>http://xzh.me/posts/emperorsnewmind/</link>
      <pubDate>Sun, 12 Jul 2015 00:00:00 +0000</pubDate>
      
      <guid>http://xzh.me/posts/emperorsnewmind/</guid>
      <description>Finally finished reading Roger Penrose&amp;rsquo;s classic book &amp;ldquo;The Emperor&amp;rsquo;s New Mind: Concerning Computers, Minds and The Laws of Physics&amp;rdquo;. As a junior Ph.D. student who hopes to have a career in the research of artificial intelligence (machine learning or deep learning more precisely), I was reading this book as a touch on the opposite of the belief that intelligence is achievable by machines. Apart from several of his dramatic tones towards mocking A.</description>
    </item>
    
    <item>
      <title>One Precondition for Intelligence</title>
      <link>http://xzh.me/posts/precondition/</link>
      <pubDate>Tue, 21 Apr 2015 00:00:00 +0000</pubDate>
      
      <guid>http://xzh.me/posts/precondition/</guid>
      <description>Medical study shows that two consciousness could exist in the same body, if the connection between the left and the right brain hemispheres are damaged. Does this medical fact tells us something more about intelligence? My opinion is, it is an evidence for the hypothesis that certain deficiency in low-level communication is a precondition for intelligence. I know that sounds crazy or perhaps hard to understand, but please allow me to explain.</description>
    </item>
    
  </channel>
</rss>