<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Intelligence on Xiang Zhang</title>
    <link>http://xzh.me/categories/intelligence/</link>
    <description>Recent content in Intelligence on Xiang Zhang</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Thu, 28 Jan 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://xzh.me/categories/intelligence/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Common Sense: Unsupervised Learning or Machine Evolution?</title>
      <link>http://xzh.me/posts/commonsense/</link>
      <pubDate>Thu, 28 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>http://xzh.me/posts/commonsense/</guid>
      <description>&lt;p&gt;Today I saw a post from Mark Zuckerberg on his project of automating a home. That great project is so awesome that it could probably change the future of human living. Along with the post there are arguments that common sense may be obtained through unsupervised learning. But personally I do not buy these arguments, at least not in the current form of unsupervised learning.&lt;/p&gt;

&lt;p&gt;The intuition that a model can obtain common sense through unsupervised process is not straightforward to me. If that intuition came from how we human beings obtain common sense, a large portion of it came from a well-designed and strongly-supervised form of teaching and learning in school. Even prior to school, we learn via a feedback process with the world we interact, and at the same time under a strongly-supervised &amp;lsquo;protection&amp;rsquo; from our parents. There are many many different feedback signals available to us.&lt;/p&gt;

&lt;div id=&#34;fb-root&#34;&gt;&lt;/div&gt;&lt;script&gt;(function(d, s, id) {  var js, fjs = d.getElementsByTagName(s)[0];  if (d.getElementById(id)) return;  js = d.createElement(s); js.id = id;  js.src = &#34;//connect.facebook.net/en_US/sdk.js#xfbml=1&amp;version=v2.3&#34;;  fjs.parentNode.insertBefore(js, fjs);}(document, &#39;script&#39;, &#39;facebook-jssdk&#39;));&lt;/script&gt;&lt;div class=&#34;fb-post&#34; data-href=&#34;https://www.facebook.com/zuck/posts/10102620559534481&#34; data-width=&#34;500&#34;&gt;&lt;div class=&#34;fb-xfbml-parse-ignore&#34;&gt;&lt;blockquote cite=&#34;https://www.facebook.com/zuck/posts/10102620559534481&#34;&gt;&lt;p&gt;My personal challenge for 2016 is to build a simple AI -- like Jarvis from Iron Man -- to help run my home and help me...&lt;/p&gt;Posted by &lt;a href=&#34;https://www.facebook.com/zuck&#34;&gt;Mark Zuckerberg&lt;/a&gt; on&amp;nbsp;&lt;a href=&#34;https://www.facebook.com/zuck/posts/10102620559534481&#34;&gt;Wednesday, January 27, 2016&lt;/a&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;On the other hand, if we think about the entire knowledge of human race, common sense seems to come unsupervisedly in the sense that we generate it via thousands years of evolution. But again that relies on the fact that the human race is not a single individual &amp;ndash; it consists of many many individuals and only through this complicated dynamic system we form what we today call common sense. Therefore it seems to miss the point to ask a single unsupervised model to generate all of common sense.&lt;/p&gt;

&lt;p&gt;However, I also feel that this seemingly unsupervised process of evolution is not feedback-free. Any living creature had to strive for maintain its low-entropy state (a structured state constituting of cells and their internal orderly structure), and release high-entropy waste to the environment via metabolism. Massive energy is used by such a creature during the process. It is through the will of better maintaining this low-entropy state that we evolve. Of course, machines do not have to do this, they just have to make &amp;lsquo;surving humans&amp;rsquo; as their ultimate goal.&lt;/p&gt;

&lt;p&gt;But the question is, how do we design a race of machines such that they can evolve to better surve us? And if this is possible, will the evolving machine population generate things similar to the phenomenon of &amp;lsquo;common sense&amp;rsquo;?&lt;/p&gt;

&lt;p&gt;P.S. Ultimately I feel it is meaningless to argue about whether something is supervised or unsupervised. In current form of machine learning one always needs to do optimization, therefore one needs to design an objective. We can always argue that the objective is a kind of supervised signal. The mindset of labeling something as &amp;lsquo;unsupervised&amp;rsquo; more or less misled us to think less about the mechanism of how some intelligent really phenonmena happened.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Evolve to Sum</title>
      <link>http://xzh.me/posts/evolvetosum/</link>
      <pubDate>Sat, 23 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>http://xzh.me/posts/evolvetosum/</guid>
      <description>

&lt;p&gt;Here is one simple question: how to make machines learn to sum up two numbers? Of course, this problem largely depends on how the numbers are represented. If they are represented in some finite-precision float-point format, a simple regression where both weights are one would solve the problem. But that&amp;rsquo;s not what I mean here. What I mean is, given the symbolic representation of numbers (i.e., each number is a sequence of digits), how could a machine learn to sum them up?&lt;/p&gt;

&lt;p&gt;There have been research projects in this realm, but the results are far from satisfactory and none of them can produce a machine that can sum up two numbers of arbitrary length. In this blog I want to offer an alternative view of this problem by dichotomizing learning into individual learning and evolutionary learning. Then, I provide an initial thought on the possibility of a new learning paradigm that is inspired not only from how each of us learns, but also how knowledge is formed during the entire human evolutionary process.&lt;/p&gt;

&lt;h3 id=&#34;learning-to-sum:f4c76188421e5843dda1963eace05e1c&#34;&gt;Learning to Sum&lt;/h3&gt;

&lt;p&gt;Yesterday I was invited to &lt;a href=&#34;https://www.zhihu.com/question/39727411/answer/82778981&#34;&gt;answer a question on Zhihu&lt;/a&gt;, a Chinese equivalent of Quora, about whether deep learning models can be used to learn to sum. Immediately I thought that the question is actually more difficult to answer than it appears to be, partly because it is always easier to disprove the possibility of something than to prove it.&lt;/p&gt;

&lt;p&gt;Knowing that we have very limited results in learning arithmetic operations, I started to recall a thought inspired by the book &amp;ldquo;Probably Approximately Correct: Nature’s Algorithms for Learning and Prospering in a Complex World&amp;rdquo;, written by Turing award laureate Leslie G. Valiant. The book is mainly about an analogy of the probably approximately correct (PAC) learning theory and the evolutionary process of human beings. But my thought is only tangentially related to this analogy. It is more about a limitation on the current connectionist machine learning paradigm in relation to the dichotomy of individual learning and evolutionay process.&lt;/p&gt;

&lt;p&gt;It is better explained using the problem in question &amp;ndash; summation. The way each of us learns arithmetic operations such as summation is not quite what connectionist machine learning paradigm advocates &amp;ndash; end-to-end learning by showing result examples of two numbers summing together. Rather, we learn arithmetic operations via a strongly supervised process with the help of our math teachers in elementary school. When learning to sum, each of us were not only presented with examples of correct or incorrect sums, but also the proceeding steps of this arithmetic operation. If we were to train a deep learning model to do summation in this way, we would start with perhaps a simple recurrent neural net, design a process for this network to do summation, and train the network using samples of this process in a strongly supervised fashion. We can think of ourselves as the math teachers of this student recurrent neural network, teaching it not only right from wrong but also the steps to make it right.&lt;/p&gt;

&lt;p&gt;What is missing in the learning process above is the question of where summation comes from, or even where the concept of numbers comes from. We can find inspiration of such questions in humans, but it would no longer be possible to think of it in the scope of each human individual. Rather, we would have to think of human race as a whole and find answers in its entire evolutionary process. The answer of such questions immediately becomes demystified in this way of thinking, in that the concept of numbers and the process of arithmetic comes from generations of historical human activities. First of all, there is necessity of counting because we have learnt to produce and store goods. That was the reason for the concept of numbers. Then, when human society is developed enough for each individual to produce extra goods than for himself, there comes trading. Arithmetic naturally becomes a necessity, and since then we started to dissemminate the correct way of doing arithmetic until there is education and we started to teach it generation by generation. The description here is an extremely condensed version, and a better storytellling can be found in &lt;a href=&#34;http://www.bbc.co.uk/programmes/b00dwf4f&#34;&gt;BBC&amp;rsquo;s documentary &amp;lsquo;The Story of Maths&amp;rsquo;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The discussion above also hints on one problem of current generation deep learning research. The learning paradigm we used to design models is unexceptionally individual learning. One may argue that there is some aspect of deep learning models which implements some of evolution&amp;rsquo;s achievements &amp;ndash; such as convolutional network implements an analogy of our visual cortex (not the eye &amp;ndash; the eye is analogized by a camera). But this is only a slighly blurred line between individual learning and evolutionary learning. It is apparently impossible for evolution to be responsible for every part of the visual system &amp;ndash; maybe some lower layers that detect edges, but definitely not the upper layers where we form concepts and classification of objects. It does not disprove the necessity of a evolutionary learning paradigm.&lt;/p&gt;

&lt;h3 id=&#34;evolve-to-sum:f4c76188421e5843dda1963eace05e1c&#34;&gt;Evolve to Sum&lt;/h3&gt;

&lt;p&gt;Summation and other arithmetic operations are not the only things that evolutionary learning models. Common sense, culture, art and language &amp;ndash; traditionally hard to model by connectionist ideas &amp;ndash; could also be thought of as by-products of human evolution. If we have a way to let machines to evolve themselves, it may generate its own common sense, culture and art. This is not at all what evolutionary algorithm is about &amp;ndash; we are talking about evolution of models in a more literal sense.&lt;/p&gt;

&lt;p&gt;Admittedly, there are many problems that are unclear about an evolutionary learning process. The first one is whether there is an objective for machine evolution. I personally think that this is more about what the models should do rather than what is the optimization objective. Like human beings, the goal of a machine should be about survival in the world it exists. This suggests a different design principle for machines &amp;ndash; rather than to design machines to assist our daily lives, we would design machines that strive to surve themselves. It means we must equip machines with the ability of control its own survival needs. In the context of our current generation eletronic technology, one way to do this is probably equip it with the ability to plug itself into power outlets, at least mechanically. Then, we can use our current machine learning methods to let it learn how to get plugged with power in its software.&lt;/p&gt;

&lt;p&gt;The second problem is how could machines reproduce, since only with reproduction we would have generations of machines to constitute the process of evolution. One cheap way to do this is probably take over reproduction ourselves. We can keep producing copies of such machines, and evolution becomes choosing the best surviving learning machines to initialize the new ones. When technology is advanced enough, there will probably be a time that one of the machine will learn to reproduce by themselves, but we probably would not want to give the machines such ability.&lt;/p&gt;

&lt;p&gt;The last problem is what the software of such machines should look like. I believe it should consist of three parts: perception, reasoning and action. The perception part could be on vision or sound, and there are already many models in research for this. The reasoning part is relatively new, including perhaps the current trend on using embedding and memory techniques. As for the action part, there are at least two potential models &amp;ndash; recurrent neural networks and reinforcement learning. One attempts to model the past, and the other tries to predict the future reward.&lt;/p&gt;

&lt;p&gt;Now, let&amp;rsquo;s go back to the question of learning to sum. How can we discover whether the machine can do sum? Well, I think the question is probably wrong. A better question is probably this: is computing summation a necessity for the evolution of machines?&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>On the Emperor&#39;s New Mind</title>
      <link>http://xzh.me/posts/emperorsnewmind/</link>
      <pubDate>Sun, 12 Jul 2015 00:00:00 +0000</pubDate>
      
      <guid>http://xzh.me/posts/emperorsnewmind/</guid>
      <description>&lt;p&gt;Finally finished reading Roger Penrose&amp;rsquo;s classic book &amp;ldquo;The Emperor&amp;rsquo;s New Mind: Concerning Computers, Minds and The Laws of Physics&amp;rdquo;. As a junior Ph.D. student who hopes to have a career in the research of artificial intelligence (machine learning or deep learning more precisely), I was reading this book as a touch on the opposite of the belief that intelligence is achievable by machines. Apart from several of his dramatic tones towards mocking A.I. (what was that story in the pro- and epi-logue about?), this book has been a very enjoyable experience for me.&lt;/p&gt;

&lt;p&gt;Roger Penrose is definitely one scientist that holds a very strong opinion on this opposite, and I do have to say that he is undoubtedly good at explaining his arguments. This book did a good job at disseminating a set of fundamental ideas from a physics perspective in relation to some very philosophical and mathematical issues. From my reading, there are two streams of ideas in the book. The first one is from mathematics, including the introduction of algorithms, Turing machines and logical proof systems. The second one is from physics, from classical mechanics to relativity and quantum mechanics and beyond. The interaction of these two streams by itself is worth reading by anyone who is pondering on the fundamental doubts of the mind, intelligence and conciousness.&lt;/p&gt;

&lt;p&gt;From the first stream, the book&amp;rsquo;s main argument rests on the Turing halting problem and Gödel&amp;rsquo;s incompleteness theorems. From these theorems, he argues that machines could not be like humans since it could not know the truthness of these self-referencing statements. I am not yet convinced by this seemingly sound argument, because it rests on the fact that there is certain statement about the system itself that it could not know true or false. We humans could perceive that these incomplete statements are true, because we are not these systems therefore they are not self-referencing statements for ourselves. We do not have an answer to whether we ourselves are free from these incomplete limitations, since if we had the answer it would violate the incompleteness theorems. Who knows, maybe some aliens would think of us as no difference from we think of the machines, and apply a form of Cantor&amp;rsquo;s diagonalization to say that &amp;ldquo;look, humans cannot have mind because they cannot understand these true statements that are obvious to us&amp;rdquo;! As a result, the presumption that humans are free from incompleteness is one most ridiculous hidden idea in the book.&lt;/p&gt;

&lt;p&gt;In the second stream, the book became much more constructive. It is a great journey to explore the searching of an explanation for the mind through the vast space of knowledge in physics. However, throughout the arguments, the ideas could only belong to a set of speculations. This is not a surprise since he argues for the necessity of a correct quantum gravity (CQG) theory to explain the human mind, which should ultimately unify quantum mechanics and general relativity under a single mathematical framework. It is the fact that no such theory yet exists that shakes down many of his arguments and made them merely speculations. As a result, this book in my opinion does a very bad job at opposing artificial intelligence in both streams.&lt;/p&gt;

&lt;p&gt;In general, the book is still very much enjoyable just because it contains a grand set of fundamental knowledge. It is particularly so reading from a critic point of view. Roger Penrose also has two later books in the same string of thought, which undoubtedly may explain his ideas better and may resolve some of this book&amp;rsquo;s issues. I am looking forward to reading them as valuable thought excercises, but may be after a few books from some other human endeavors.&lt;/p&gt;

&lt;p&gt;Finally, here is a video where Roger Penrose explains some of his ideas. Watch with a critic&amp;rsquo;s mind!&lt;/p&gt;

&lt;div class=&#34;embed video-player&#34; style=&#34;text-align: center;&#34;&gt;
&lt;iframe class=&#34;youtube-player&#34; type=&#34;text/html&#34; width=&#34;640&#34; height=&#34;385&#34; src=&#34;http://www.youtube.com/embed/eVq39QbFQXE&#34; allowfullscreen frameborder=&#34;0&#34;&gt;
&lt;/iframe&gt;
&lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>One Precondition for Intelligence</title>
      <link>http://xzh.me/posts/precondition/</link>
      <pubDate>Tue, 21 Apr 2015 00:00:00 +0000</pubDate>
      
      <guid>http://xzh.me/posts/precondition/</guid>
      <description>

&lt;p&gt;Medical study shows that two consciousness could exist in the same body, if the connection between the left and the right brain hemispheres are damaged. Does this medical fact tells us something more about intelligence? My opinion is, it is an evidence for the hypothesis that certain deficiency in low-level communication is a precondition for intelligence. I know that sounds crazy or perhaps hard to understand, but please allow me to explain.&lt;/p&gt;

&lt;h3 id=&#34;a-different-understanding-of-alien-hand-syndrome:45530e5fe76f4db5de7bc9f517c17a55&#34;&gt;A Different Understanding of Alien Hand Syndrome&lt;/h3&gt;

&lt;p&gt;This Friday night I was watching the rather dramatized and thrilling episodes of &amp;ldquo;Dark Matters: Twisted But True&amp;rdquo;. In episode 4 of season 1, there is a story about alien hand syndrome, a rare neurological disorder that causes hand movement without the person being aware of what is happening or having control over the action. In the story, a woman&amp;rsquo;s left hand tried to kill herself without her being able to control it. After some thrilling mood rendering, it was revealed that her brain had some permanent damage resulted from a stroke prior to the syndrome. The problem was that the connection between her brain&amp;rsquo;s left and right hemispheres was broken, and it created two consciousness in the same body.&lt;/p&gt;

&lt;p&gt;This reminds me of a similar illustration in Dr. Michio Kaku&amp;rsquo;s recent book of popular science &amp;ndash; &amp;ldquo;The Future of the Mind: The Scientific Quest to Understand, Enhance, and Empower the Mind&amp;rdquo; &amp;ndash; in whose chapter 1 there is a section named &amp;ldquo;The Split-Brain Paradox&amp;rdquo;. It features the research by Dr. Roger Sperry, a Nobel laureate who studied the effects of split-brain, in particular the fact that two consciousness could exist in the two hemispheres if the connection between them is broken. He also imagined that &amp;ldquo;both the left and the right hemisphere may be conscious simultaneously in different, even in mutually conflicting, mental experiences that run along in parallel.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;Following Dr. Roger Sperry&amp;rsquo;s thought, both the TV show episode and Dr. Michio Kaku&amp;rsquo;s book posit on the possibility that there are two consciousness existing in everone&amp;rsquo;s mind at every moment. Dr. Michio Kaku even interviewed Dr. Michael Gazzaniga of the University of California, Santa Barbara, for how experiments can be done to test the theory. The book mentioned a safe way to communicate separately to each hemisphere without the knowledge of the other, and it sucessfully shows that two hemispheres would give different answers to the same question.&lt;/p&gt;

&lt;p&gt;However, there is an apparent logical flaw in the above mentioned thought and the corresponding experiments. This is one very apparent example of causation fallacy, in which there are two possible causal reasoning routines to explain the same results. One is of course, as Dr. Sperry and Dr. Kaku believe, that there were two consciousness exist in the same skull for anyone at any time. The other obvious and often ommitted possibility is that there was only one consciousness in one&amp;rsquo;s brain, until there is a physical disconnection between the two hemispheres.&lt;/p&gt;

&lt;p&gt;If you ask me which theory I believe, I would say the second one. This is because to prove the first theory, one would have to show that when the two hemispheres are in normal connection there exists two consciousness at the same time. This is unlikely to be successful because normal people apparently posit themselves as one whole consciousness with coherent behavior in all body parts. One may wonder then, how about dissociative identity disorder (DID) in which one person could have multiple personalities? Well, the answer is that it does not disqualify our second theory because the disorder does not show multiple personalities at the same time. Rather, multiple dissociated personality states would alternately control a person&amp;rsquo;s behavior.&lt;/p&gt;

&lt;p&gt;One can debate the causation fallacy above endlessly untill some experiments can be done to prove one and disprove the other. But before that, I will assume the second theory is true throughout the rest of the blog.&lt;/p&gt;

&lt;h3 id=&#34;communication-not-as-a-part-of-intelligence:45530e5fe76f4db5de7bc9f517c17a55&#34;&gt;Communication (not?) as a Part of Intelligence&lt;/h3&gt;

&lt;p&gt;The focus of the split-brain phenomenon rests on the connection between left and right hemispheres. If the connection is broken, then one can easily see signs of two consciousness. This means that to be a coherent intelligent entity, the place in which consciousness exists (in this case the brain) must have proper physical connection inside its every component. The necessity of such connection suggests that communication is a crucial part for intelligence.&lt;/p&gt;

&lt;p&gt;However, communication itself is an ambiguous word. For example, communication between humans could mean natural languages, facial expressions or body movements. One usually thinks that this type of communication is different from the type between the two hemispheres of the brain &amp;ndash; which consists of eletronic activity and chemical reactions. If we consider each human as an intelligent entity, then I will call the first kind a high-level communication, and the second kind inside brain as low-level communication. With this dichotomy, I can explain things in a much clearer fashion.&lt;/p&gt;

&lt;p&gt;In the famous paper &amp;ldquo;Computing Machinery and Intelligence&amp;rdquo;, Alan Turing argues that the Turing test could be a philosophical definition for intelligence. The test is essentially deciding whether a machine has intelligence by how good it immitates a human. The decision is made by the judge in a probably and approximately correct way, by trying to distinguish between the machine and the human through questioning and answering. This implicitly indicates that communication (the questioning and answering process) is necessary in deciding whether a machine has intelligence. This is true at least for humans, who unanimously think of each other as an intelligent entity.&lt;/p&gt;

&lt;p&gt;One thing I do not think Turing test encompasses is the possibility of intelligence that does not communicate with humans, and also intelligence that is different from or beyond human comprehension. It only judges whether something is intelligence using one unanimously agreed intelligent entity - human, but I do not believe human is the only possible intelligent entity. It is possible for intelligent machines to communicate with each other in a language that is not English or Chinese, but still could be thought of as being intelligent. However, in philosophy there is probably no better way to define intelligence other than Turing test, because intelligence is a meaningless entity in many people&amp;rsquo;s belief. This belief may even include the definition itself.&lt;/p&gt;

&lt;p&gt;All the above discussions are about high-level communication. I think that people can argue endlessly about whether high-level communication is a necessity for intelligence, and I just gave one example above. On the other hand, the question that whether low-level communication is necessary for intelligence is not an ambiguous question in my opinion, especially for the boundary of something being one or multiple intelligent entity. This is already proved by the alient hand syndrome mentioned in the previous section &amp;ndash; low-level communication is a necessity.&lt;/p&gt;

&lt;h3 id=&#34;one-precondition-for-intelligence:45530e5fe76f4db5de7bc9f517c17a55&#34;&gt;One Precondition for Intelligence&lt;/h3&gt;

&lt;p&gt;Of course, being intelligent alone seems very meaningless. The meaning of being intelligent, at least in the sense for humans, partially rests in the fact that we can communicate with other intelligent entities. On the other hand, if Turing&amp;rsquo;s definition on intelligence is correct, then to decide whether some machine is intelligence at least two other intelligent entities must present &amp;ndash; one to be immitated and the other the judge. Combining with out previous discussion on high-level and low-evel communication, this seemingly boring reasoning gives us a quite striking conclusion: one necessity for the existence of intelligence is that there must be certain deficiency in low-level communication.&lt;/p&gt;

&lt;p&gt;The reason that low-level communication must be deficient for there to be multiple intelligent entity is because if there was low-level communication, the supposedly different intelligent entity would better end up being one intelligence. Speaking in a more abstract way, this makes sense because if low-level communication was efficient, making all the intelligent components a coherent single intelligent entity is simply also more efficient. This analogy is actually being used by software and hardware engineers everyday, such as we never transfer data across the Internet if it was simply a memory copy inside the same computer.&lt;/p&gt;

&lt;p&gt;An acute reader might question at this point that I was not able to define in a clear way what is the difference between low-level and high-level communication. You are right. All that I can say about the difference between low-level and high-level communication is relative to humans. We ought to think natural language as a form of high-level communication, and the electronic and chemical reactions happening in our brain as a form of low-level communication. The reason why we need natural language in the first place is that we want to be more efficient as a whole, under the precondition that low-level communication is deficient.&lt;/p&gt;

&lt;p&gt;Such relativity has more profound implications. It is an open question whether relative to a country, the communication between its citizens is a low-level one whereas the political agenda in between contries is a form of high-level communication, although the former one is by the means of natural languages. If such hypothesis could be modeled in a computational way, this may open another possibility of modeling society by computation. Then, this could probably enable us to use rigorous methamatics to analyze both societies and individuals, by assuming they are relative intelligent entities.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>